# AccuKnox-AIML
Problem Statement 1:

1-API Data Retrieval and StorageðŸ“‚:fetch_books_api.py

2-Data Processing and VisualizationðŸ“‚: student_scores_analysis.py

3-CSV Data Import to a DatabaseðŸ“‚:csv_to_db.py

4-complex python code written - https://github.com/sanjay-2605/Job-rec-AI/blob/main/app.py

Code: main code regarding my personal project named Job recommondation AI app

Most Complex Python Code:

AI-based Job Recommendation System built using Python and Streamlit.
The application takes user skills as input, performs TF-IDF vectorization and cosine similarity to match skills with job requirements and generates personalized career guidance using an LLM API. The project integrates data processing, machine learning techniques, API usage and an interactive UI in a single application.

5- complex database code-

Code:https://github.com/sanjay-2605/Personal-Finance-Tracker-Project/blob/main/sql_db.sql

Most Compelex DataBase code:

This SQL script defines a normalized database schema for a personal finance tracker application. It includes tables for users, categories and transactions, designed with appropriate primary keys and foreign keys to model relationships. The script also includes sample data inserts and analytical queries that compute total income, total expenses, category-wise spending breakdown and remaining balance. These analytical queries demonstrate the use of SQL joins, aggregations and conditional filtering. The schema and queries together show practical use of SQL that could support dashboard reporting or backend data summaries in a finance app.

Problem Statement 2:

1-Where would you rate yourself on (LLM, Deep Learning, AI, ML). A, B, C [A = can code independently; B = can code under supervision; C = have little or no understanding]


| Area                             | Rating | Explanation                                                                                                                                                                                                                                                                    |
| -------------------------------- | ------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| **Artificial Intelligence (AI)** | **B**  | I have a practical understanding of AI concepts such as problem formulation, rule-based systems, and ML-driven decision making. I can build basic AI applications and integrate existing AI tools under supervision while continuing to strengthen fundamentals.               |
| **Machine Learning (ML)**        | **B**  | I understand core ML concepts including supervised and unsupervised learning, feature extraction, model evaluation, and basic algorithms. I can implement ML solutions with guidance and have hands-on exposure through small projects and experimentation.                    |
| **Deep Learning (DL)**           | **C**  | I have a foundational theoretical understanding of neural networks and deep learning concepts, but limited hands-on implementation experience. I am actively learning architectures and training workflows to move toward practical usage.                                     |
| **Large Language Models (LLMs)** | **B**  | I have a conceptual understanding of how LLMs work, including prompting and basic API usage, but limited experience building end-to-end LLM systems independently. I am currently focusing on learning LLM architectures, prompt design and integration patterns such as RAG. |

2-What are the key architectural components to create a chatbot based on LLM? Please explain the approach on a high-level

Key Architectural Components of an LLM-Based Chatbot (High-Level)-

An LLM-based chatbot is a system that combines user interaction layers, backend services, language models and supporting infrastructure to generate meaningful and context-aware responses. The architecture is modular so that each component can evolve independently.

1. User Interface (UI)-

The user interface is the entry point for user interaction. It can be a web application, mobile app or chat interface.

Responsibilities:

Capture user input (text or voice)

Display chatbot responses

Handle basic input validation

The UI is typically kept lightweight and delegates processing to backend services.

2. Backend Application Layer-

The backend acts as the orchestrator of the system. It receives user input from the UI and manages the interaction with downstream components.

Responsibilities:

API request handling

Authentication and rate limiting

Session and conversation management

Calling the LLM and other services

This layer ensures separation between the UI and AI logic.

3. Prompt Engineering & Context Management-

Prompt engineering defines how user input is structured before being sent to the LLM.

Responsibilities:

Combine system instructions, user queries and conversation history

Apply role-based prompts (system, user, assistant)

Control response tone, format and constraints

Effective prompt design is critical for producing consistent and relevant responses.

4. Large Language Model (LLM)-

The LLM is the core intelligence of the chatbot.

Responsibilities:

Understand natural language input

Generate context-aware and coherent responses

Perform reasoning, summarization or explanation tasks

The LLM can be accessed through an API or deployed locally depending on scale and security needs.

5. Retrieval & Context Injection Layer-

This layer connects the vector database with the LLM.

Responsibilities:

Convert user queries into embeddings

Retrieve top-K relevant documents

Inject retrieved content into the prompt

This improves factual accuracy and reduces hallucinations.

6. Response Post-Processing & Safety Layer-

After the LLM generates a response, additional processing may be applied.

Responsibilities:

Filter unsafe or inappropriate content

Enforce formatting rules

Apply business or policy constraints

This layer is especially important in production systems.

7. Logging, Monitoring & Feedback Loop-

To continuously improve the chatbot, monitoring and feedback mechanisms are essential.

Responsibilities:

Log user interactions and responses

Track latency, errors and quality metrics

Collect user feedback for future improvement

This data can be used to refine prompts, retrieval logic, or system behavior.

High-Level Workflow-

User â†’ UI â†’ Backend â†’ Prompt Builder
                    â†“
           (Optional) Vector Database
                    â†“
                  LLM
                    â†“
           Post-Processing & Safety
                    â†“
                  User

Summary-

An LLM-based chatbot is not just a language model but a system of coordinated components. The effectiveness of the chatbot depends on how well these componentsâ€”UI, backend orchestration, prompt design, retrieval mechanisms and monitoringâ€”work together. This modular architecture allows the system to scale, adapt to new data and improve response quality over time.                

3-Please explain vector databases. If you were to select a vector database for a hypothetical problem (you may define the problem) which one will you choose and why?

Vector Databases: Concept, Use Case and Selection

Vector Database-

A vector database is a specialized database designed to store and search vector embeddings, which are numerical representations of data such as text, images, audio, or code. These embeddings capture the semantic meaning of data rather than exact keyword matches.

Unlike traditional databases that rely on exact matching or indexing of structured fields, vector databases enable similarity search. This allows the system to retrieve items that are semantically similar to a query using distance metrics such as cosine similarity, Euclidean distance or dot product.

Why Vector Databases Are Needed-

Large Language Models (LLMs) have limited context windows and do not have access to private or frequently changing data. Vector databases solve this problem by enabling:

Semantic search over large document collections

Retrieval of relevant context for LLMs

Improved factual accuracy using external data

Scalable and fast similarity-based retrieval

This approach is commonly used in Retrieval-Augmented Generation (RAG) systems.

Core Components of a Vector Database-

Embedding Storage â€“ Stores high-dimensional vectors representing data

Indexing Engine â€“ Enables efficient nearest-neighbor search

Similarity Metrics â€“ Measures closeness between vectors

Metadata Storage â€“ Stores additional structured information

Query Engine â€“ Handles similarity and filtered search

Hypothetical Problem Definition

Problem:
Build an internal chatbot for a company that can answer employee questions based on internal documents such as policies, onboarding guides and technical documentation.

Constraints:

Documents are frequently updated

Data must remain private

Fast and accurate responses are required

System should integrate easily with Python and LLMs

Approach Using a Vector Database

Convert documents into text chunks

Generate embeddings for each chunk using an embedding model

Store embeddings and metadata in a vector database

Convert user queries into embeddings

Retrieve the most similar document chunks

Inject retrieved context into the LLM prompt (RAG)

Selected Vector Database: FAISS
 FAISS?-

For the given problem, I would choose FAISS (Facebook AI Similarity Search).

Reasons:

Open-source and free

Highly optimized for fast similarity search

Easy integration with Python

Suitable for small to medium-scale datasets

Can run completely locally, ensuring data privacy

FAISS is particularly well-suited for prototyping and internal tools where simplicity, performance and control over data are important.




